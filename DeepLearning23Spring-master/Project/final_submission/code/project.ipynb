{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir(sys.path[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备 yolo 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "weights_path = 'D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\\\final_submission\\input\\\\best.weights'\n",
    "configuration_path = 'D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\\\final_submission\\input\\yolov3.cfg'\n",
    "probability_minimum = 0.5\n",
    "threshold = 0.3\n",
    "\n",
    "def get_model(weights_path, configuration_path):\n",
    "    return cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\n",
    "\n",
    "# 实例化模型\n",
    "network = get_model(weights_path, configuration_path)\n",
    "\n",
    "# 获取所有层的 list\n",
    "layers_names_all = network.getLayerNames()\n",
    "\n",
    "# 加载 COCO labels\n",
    "labels = open('D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\\\final_submission\\input\\coco.names').read().strip().split('\\n')\n",
    "\n",
    "# 获取 ouput 层\n",
    "layers_names_output = [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
    "# Check point\n",
    "print(layers_names_output)  # ['yolo_82', 'yolo_94', 'yolo_106']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义图像处理识别函数（yolo）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(blob, frame, shape, left, top):\n",
    "    network.setInput(blob)  # 将 blob 作为网络输入\n",
    "\n",
    "    # 查看 forward 运行时间\n",
    "    # start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    # end = time.time()\n",
    "    # print('YOLO v3 took {:.5f} seconds'.format(end - start))\n",
    "\n",
    "    # 为每个 label 获取随机颜色以标识\n",
    "    np.random.seed(42)\n",
    "    # randint(low, high=None, size=None, dtype='l')\n",
    "    colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "    # 为每个检测到的物体初始化 list\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    # 获取原 input 图片的维度\n",
    "    h, w = shape[:2]\n",
    "    # h *= 480 // shape[0]\n",
    "    # w *= 640 // shape[1]\n",
    "\n",
    "    for result in output_from_network:\n",
    "    # 遍历 output 层的所有检测对象\n",
    "        for detection in result:\n",
    "            # 获取当前对象的 class\n",
    "            scores = detection[5:]\n",
    "            class_current = np.argmax(scores)\n",
    "\n",
    "            # 获取当前对象的置信度\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            # 只保留置信度大于阈值的对象\n",
    "            if confidence_current > probability_minimum:\n",
    "                # 将 bounding box 缩放以适应原来的 input 图片\n",
    "                box_current = detection[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "                x_min = int(x_center - (box_width / 2)) + left\n",
    "                y_min = int(y_center - (box_height / 2)) + top\n",
    "                \n",
    "                print(\"x_min: \", x_min)\n",
    "                print(\"y_min: \", y_min)\n",
    "\n",
    "                # 将结果添加到准备好的 list 中\n",
    "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    # 使用非极大值抑制来获得最终结果 bounding box\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "\n",
    "    for i in range(len(class_numbers)):\n",
    "        print(labels[int(class_numbers[i])])\n",
    "\n",
    "    # 绘画 bounding box\n",
    "    if len(results) > 0:\n",
    "        # 遍历 results\n",
    "        for i in results.flatten():\n",
    "            # 获取当前 bounding box 坐标\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            # 获取当前 bounding box 颜色\n",
    "            colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n",
    "\n",
    "            # 绘图\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
    "                        colour_box_current, 5)\n",
    "\n",
    "            # 输出 label 以及其置信度\n",
    "            text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n",
    "\n",
    "            # 将文字加入\n",
    "            cv2.putText(frame, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8, colour_box_current, 2)\n",
    "            \n",
    "    return frame\n",
    "\n",
    "\n",
    "# image_input = cv2.imread('D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\yolo3-cat\\input\\images\\\\cup.jpg')\n",
    "# # Getting image shape\n",
    "# image_input_shape = image_input.shape\n",
    "# blob = cv2.dnn.blobFromImage(image_input, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "# detect_img(blob)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "# plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义手势收集模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_custom_gesture(path, to_path):\n",
    "    # 初始化MediaPipe的手部识别模型\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.75,\n",
    "        min_tracking_confidence=0.75)\n",
    "\n",
    "    # 设置绘制工具\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # 指定包含图片的文件夹路径\n",
    "    folder_path = path\n",
    "\n",
    "    # 遍历文件夹中的所有图片文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # 构造图片的完整路径\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # 加载图像\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # 将图像从BGR转换为RGB格式（MediaPipe使用RGB格式）\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 执行手部关键点识别\n",
    "            results = hands.process(image_rgb)\n",
    "\n",
    "            # 绘制关键点\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # 保存识别后的图片\n",
    "            output_path = os.path.join(to_path, 'recognized_' + filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "\n",
    "\n",
    "\n",
    "path = \"D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\\\final_submission\\code\\custom_gesture\"\n",
    "to_path = \"D:\\FDU\\Sophomore_semester2\\Deep_learning\\Project\\\\final_submission\\code\\\\recognized_custom_gesture\"\n",
    "save_custom_gesture(path, to_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义手势识别比对模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recognized_hand_gesture(path):\n",
    "    gesture_results = []  # 创建一个空列表，用于保存每个图片的识别结果\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.75,\n",
    "        min_tracking_confidence=0.75)\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image_rgb)\n",
    "            # 将手势识别的结果保存到gesture_results列表中\n",
    "            gesture_results.append(results.multi_hand_landmarks[0])\n",
    "\n",
    "    return gesture_results\n",
    "\n",
    "# 运行函数得到个性化手势信息\n",
    "custom_gesture_info = load_recognized_hand_gesture(path) # 0-清除、1-加入购物车、2-购买\n",
    "\n",
    "def calculate_angle(vector1, vector2):\n",
    "    # 计算两个向量的点积\n",
    "    dot_product = sum([a * b for a, b in zip(vector1, vector2)])\n",
    "    # 计算两个向量的模长\n",
    "    magnitude1 = math.sqrt(sum([a * a for a in vector1]))\n",
    "    magnitude2 = math.sqrt(sum([a * a for a in vector2]))\n",
    "\n",
    "    # 计算夹角（弧度）\n",
    "    angle_radians = math.acos(dot_product / (magnitude1 * magnitude2))\n",
    "\n",
    "    # 转换为角度\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "\n",
    "    return angle_degrees\n",
    "\n",
    "def get_finger_angles(hand_info):\n",
    "    # 获取手指关键点的坐标\n",
    "    thumb_tip = hand_info.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "    index_finger_tip = hand_info.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_finger_tip = hand_info.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_finger_tip = hand_info.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_info.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "    wrist = hand_info.landmark[mp.solutions.hands.HandLandmark.WRIST]\n",
    "\n",
    "    # 计算手指之间的夹角\n",
    "    thumb_angle = calculate_angle([thumb_tip.x - wrist.x, thumb_tip.y - wrist.y, thumb_tip.z - wrist.z],\n",
    "                                  [index_finger_tip.x - wrist.x, index_finger_tip.y - wrist.y, index_finger_tip.z - wrist.z])\n",
    "    index_angle = calculate_angle([index_finger_tip.x - wrist.x, index_finger_tip.y - wrist.y, index_finger_tip.z - wrist.z],\n",
    "                                  [middle_finger_tip.x - wrist.x, middle_finger_tip.y - wrist.y, middle_finger_tip.z - wrist.z])\n",
    "    middle_angle = calculate_angle([middle_finger_tip.x - wrist.x, middle_finger_tip.y - wrist.y, middle_finger_tip.z - wrist.z],\n",
    "                                   [ring_finger_tip.x - wrist.x, ring_finger_tip.y - wrist.y, ring_finger_tip.z - wrist.z])\n",
    "    ring_angle = calculate_angle([ring_finger_tip.x - wrist.x, ring_finger_tip.y - wrist.y, ring_finger_tip.z - wrist.z],\n",
    "                                 [pinky_tip.x - wrist.x, pinky_tip.y - wrist.y, pinky_tip.z - wrist.z])\n",
    "\n",
    "    return thumb_angle, index_angle, middle_angle, ring_angle\n",
    "\n",
    "def compare_hand_gesture(recognized_hand_info, present_hand_info):\n",
    "    # 获取识别手势和当前手势的手指夹角\n",
    "    recognized_angles = get_finger_angles(recognized_hand_info)\n",
    "    present_angles = get_finger_angles(present_hand_info)\n",
    "\n",
    "    # 设定夹角阈值\n",
    "    angle_threshold = 15  # 可根据需要进行调整\n",
    "\n",
    "    # 判断手势\n",
    "    if all(abs(recognized_angles[i] - present_angles[i]) <= angle_threshold for i in range(4)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义手势 2 识别函数：加入购物车手势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_buy(hand_landmarks, isCustom):\n",
    "    if isCustom:\n",
    "        return compare_hand_gesture(hand_landmarks, custom_gesture_info[1])\n",
    "    # 获取各个手指关键点的坐标\n",
    "    thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "    index_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "    # 计算拇指和食指之间的距离\n",
    "    distance = np.linalg.norm([thumb_tip.x - index_finger_tip.x, thumb_tip.y - index_finger_tip.y, thumb_tip.z - index_finger_tip.z])\n",
    "\n",
    "    # 计算其他手指与腕部的距离\n",
    "    thumb_to_palm = np.linalg.norm([thumb_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                    thumb_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                    thumb_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    ring_to_palm = np.linalg.norm([ring_finger_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                ring_finger_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                ring_finger_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    pinky_to_palm = np.linalg.norm([pinky_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                pinky_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                pinky_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    distance_to_palm = thumb_to_palm + ring_to_palm + pinky_to_palm\n",
    "    \n",
    "    # print(\"dis\", distance)\n",
    "    # print(\"palm\", distance_to_palm)\n",
    "    # 设置\"OK手势\"的阈值\n",
    "    threshold_distance = 0.08\n",
    "    threshold_palm = 0.67\n",
    "\n",
    "    if distance < threshold_distance and distance_to_palm > threshold_palm:\n",
    "        # 检测到\"OK手势\"\n",
    "        return True\n",
    "    else:\n",
    "        # 非\"OK手势\"\n",
    "        return False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义手势 3 识别函数：购买手势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_pay(hand_landmarks, isCustom):\n",
    "    if isCustom:\n",
    "        return compare_hand_gesture(hand_landmarks, custom_gesture_info[2])\n",
    "    # 获取各个手指关键点的坐标\n",
    "    thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "    index_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_finger_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "    # 计算手指之间的相对位置关系\n",
    "    index_finger_dis = np.linalg.norm([index_finger_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                         index_finger_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                         index_finger_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    middle_finger_dis = np.linalg.norm([middle_finger_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                         middle_finger_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                         middle_finger_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "\n",
    "\n",
    "    # 计算其他手指与腕部的距离\n",
    "    thumb_to_palm = np.linalg.norm([thumb_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                    thumb_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                    thumb_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    ring_to_palm = np.linalg.norm([ring_finger_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                ring_finger_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                ring_finger_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    pinky_to_palm = np.linalg.norm([pinky_tip.x - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].x,\n",
    "                                pinky_tip.y - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].y,\n",
    "                                pinky_tip.z - hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST].z])\n",
    "    distance_to_palm = thumb_to_palm + ring_to_palm + pinky_to_palm\n",
    "    \n",
    "    # 设置阈值\n",
    "    threshold_palm = 0.65\n",
    "\n",
    "\n",
    "    index_finger_second_joint = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_PIP]\n",
    "    standard = np.linalg.norm([index_finger_tip.x - index_finger_second_joint.x,\n",
    "                                                        index_finger_tip.y - index_finger_second_joint.y,\n",
    "                                                        index_finger_tip.z - index_finger_second_joint.z])\n",
    "\n",
    "    is_index_up = False\n",
    "    is_middle_up = False\n",
    "\n",
    "    if index_finger_dis > 4 * standard and index_finger_dis > 0.25:\n",
    "        # print(\"index ok!\")\n",
    "        is_index_up = True\n",
    "    if middle_finger_dis > 4 * standard and middle_finger_dis > 0.25:\n",
    "        # print(\"middle ok!\")\n",
    "        is_middle_up = True\n",
    "    # print(\"index\", is_index_finger_up)\n",
    "    # print(\"middle\", is_middle_finger_up)\n",
    "    # print(distance_to_palm)\n",
    "\n",
    "    # 判断手势是否符合 \"耶\" 手势的条件\n",
    "    if is_index_up and is_middle_up and distance_to_palm < threshold_palm:\n",
    "        # print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备人脸识别模块：付款"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] encoding features of the known faces in directory /Name...\n"
     ]
    }
   ],
   "source": [
    "def faces_paths(folder):\n",
    "    faces_list = []\n",
    "    for path, subdirs, files in os.walk(folder):\n",
    "        for name in files:\n",
    "            if not name.startswith('.'):\n",
    "                faces_list.append( os.path.join(path, name))\n",
    "    return faces_list\n",
    "\n",
    "def load_feature_face(picture_list):\n",
    "    a_encodings =[]\n",
    "    for a in picture_list:\n",
    "        file = face_recognition.load_image_file(a)\n",
    "        if file is None: \n",
    "            continue\n",
    "        face_locations = face_recognition.face_locations(file)\n",
    "        encodings = face_recognition.face_encodings(file, face_locations)\n",
    "\n",
    "        if encodings is None or len(encodings)<=0: \n",
    "            continue\n",
    "        a_encodings.append(encodings[0])\n",
    "    return a_encodings\n",
    "\n",
    "# Get the known face encodings of all the pic in directory Name\n",
    "print(\"[INFO] encoding features of the known faces in directory /Name...\")\n",
    "textColor = (255, 0, 0)\n",
    "\n",
    "mypath_a = \"D:/FDU/Sophomore_semester2/Deep_learning/Project/final_submission/code/Name\"\n",
    "a_list = faces_paths(mypath_a)\n",
    "known_face_encodings = load_feature_face(a_list)\n",
    "known_face_names = a_list\n",
    "\n",
    "# Initialize variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "\n",
    "scale_ratio = 0.5\n",
    "font = ImageFont.truetype('D:/FDU/Sophomore_semester2/Deep_learning/Project/final_submission/code/SimSun.ttf', 15, encoding=\"utf-8\")\n",
    "\n",
    "checking_name = False\n",
    "checking_name_count = 130\n",
    "\n",
    "def face_recognition_module(frame):\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=scale_ratio, fy=scale_ratio)\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    isMatch = False\n",
    "    for face_encoding in face_encodings:\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding,0.4)\n",
    "        name = \"Name/未知.png\"\n",
    "\n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "\n",
    "\n",
    "            name = known_face_names[first_match_index]\n",
    "            isMatch = True\n",
    "\n",
    "        face_names.append(name)\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            sr = int(1/scale_ratio)\n",
    "            top *= sr\n",
    "            right *= sr\n",
    "            bottom *= sr\n",
    "            left *= sr\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            board_height = int((bottom-top)/5)\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - board_height), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "            lable_name = name[-17:-4]\n",
    "            frame_pil = Image.fromarray(frame)  #转为PIL的图片格式\n",
    "            text_size = font.getsize(lable_name)\n",
    "            ImageDraw.Draw(frame_pil).text((left + ((right-left)-text_size[0])/2, bottom - board_height+(board_height-text_size[1])/2), lable_name, (255, 255, 255), font)\n",
    "            frame = np.array(frame_pil)\n",
    "    if isMatch:\n",
    "        return frame, isMatch, lable_name\n",
    "    return frame, isMatch, None\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huangzisu\\AppData\\Local\\Temp\\ipykernel_13536\\1069472135.py:86: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
      "  text_size = font.getsize(lable_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "left_top_corner: (315, 202)\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "match\n",
      "right_bottom_corner: (399, 207)\n",
      "Cropped Image Shape: (5, 84, 3)\n",
      "Cropped Image Size: 1260\n",
      "left_top_corner: (282, 200)\n",
      "right_bottom_corner: (381, 307)\n",
      "Cropped Image Shape: (107, 99, 3)\n",
      "Cropped Image Size: 31779\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "match\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "match\n",
      "left_top_corner: (224, 31)\n",
      "right_bottom_corner: (456, 218)\n",
      "Cropped Image Shape: (187, 232, 3)\n",
      "Cropped Image Size: 130152\n",
      "x_min:  224\n",
      "y_min:  25\n",
      "x_min:  201\n",
      "y_min:  29\n",
      "x_min:  242\n",
      "y_min:  31\n",
      "x_min:  221\n",
      "y_min:  28\n",
      "x_min:  202\n",
      "y_min:  29\n",
      "x_min:  239\n",
      "y_min:  33\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "left_top_corner: (439, 197)\n",
      "right_bottom_corner: (416, 183)\n",
      "Cropped Image Shape: (14, 23, 3)\n",
      "Cropped Image Size: 966\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "match\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.75,\n",
    "        min_tracking_confidence=0.75)\n",
    "\n",
    "# 创建空白画布\n",
    "buffer = np.zeros((480,640, 3), np.uint8)\n",
    "\n",
    "# 初始画笔位置\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "# 食指悬停开启绘图相关变量\n",
    "hover_duration = 0\n",
    "hover_duration_threshold = 100  # 设置悬停的时长\n",
    "hover_distance_threshold = 6 # 设置悬停识别的敏感度\n",
    "enable_drawing = False  # 是否开始绘图\n",
    "\n",
    "index_move_distance = 100\n",
    "\n",
    "# 方框绘画坐标\n",
    "left_top_corner = None\n",
    "right_bottom_corner = None\n",
    "\n",
    "# 购买状态\n",
    "state_buy = False\n",
    "\n",
    "# 个性化状态\n",
    "isCustom = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cropped_image = None\n",
    "\n",
    "while True:\n",
    "    ######################################## 手部关键点识别 ######################################### \n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # 因为摄像头是镜像的，所以将摄像头水平翻转\n",
    "    # 不是镜像的可以不翻转\n",
    "    frame= cv2.flip(frame,1)\n",
    "    results = hands.process(frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # 关键点可视化\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # 计算手部框的坐标\n",
    "            height, width, _ = frame.shape\n",
    "            xmin, ymin, xmax, ymax = width, height, 0, 0\n",
    "\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y = int(landmark.x * width), int(landmark.y * height)\n",
    "                xmin = min(xmin, x)\n",
    "                ymin = min(ymin, y)\n",
    "                xmax = max(xmax, x)\n",
    "                ymax = max(ymax, y)\n",
    "\n",
    "            # 绘制手部框\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "            # 获取食指坐标\n",
    "            index_finger = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            pinky_finger = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "            # 将食指坐标转换为画面坐标\n",
    "            x = int(index_finger.x * frame.shape[1])\n",
    "            y = int(index_finger.y * frame.shape[0])\n",
    "\n",
    "            # 计算食指移动距离判断是否悬停并切换绘画状态\n",
    "            if prev_x and prev_y: \n",
    "                index_move_distance = np.linalg.norm([x - prev_x, y-prev_y]);\n",
    "                if index_move_distance < hover_distance_threshold and hover_duration < hover_duration_threshold:\n",
    "                    hover_duration += 1\n",
    "                else:\n",
    "                    hover_duration = 0\n",
    "            if hover_duration >= hover_duration_threshold:\n",
    "                if enable_drawing:\n",
    "                    right_bottom_corner = (x, y)\n",
    "                    print(\"right_bottom_corner:\", right_bottom_corner)\n",
    "                    cv2.rectangle(buffer, left_top_corner, right_bottom_corner, (0, 255, 0), 5)\n",
    "\n",
    "                    ################################# 商品目标检测 ##################################\n",
    "                    left = min(left_top_corner[0], right_bottom_corner[0])\n",
    "                    top = min(left_top_corner[1], right_bottom_corner[1])\n",
    "                    right = max(left_top_corner[0], right_bottom_corner[0])\n",
    "                    bottom = max(left_top_corner[1], right_bottom_corner[1])\n",
    "            \n",
    "                    cropped_image = frame[top:bottom, left:right]\n",
    "\n",
    "                    # 获取帧图像的blob\n",
    "                    print(\"Cropped Image Shape:\", cropped_image.shape)\n",
    "                    print(\"Cropped Image Size:\", cropped_image.size)\n",
    "\n",
    "                    if cropped_image.size != 0:\n",
    "                        # cropped_image = cv2.resize(cropped_image, (128, 128))\n",
    "                        blob = cv2.dnn.blobFromImage(cropped_image, 1 / 255.0, (128, 128), swapRB=True, crop=False)\n",
    "                        # 应用目标检测\n",
    "                        buffer = detect_img(blob, buffer, cropped_image.shape, left, top)\n",
    "                    ################################ 商品目标检测结束 ###############################\n",
    "                else:\n",
    "                    left_top_corner = (x, y)\n",
    "                    print(\"left_top_corner:\", left_top_corner)\n",
    "                enable_drawing = not enable_drawing\n",
    "                hover_duration = 0\n",
    "\n",
    "            #################################### 手势识别 1：清除画面 ###############################\n",
    "            # 计算食指和小指之间的距离，识别握拳以刷新绘画痕迹\n",
    "            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "            distance = np.linalg.norm([thumb_tip.x - pinky_finger.x, thumb_tip.y - pinky_finger.y, thumb_tip.z - pinky_finger.z])\n",
    "            # 设置握拳的阈值\n",
    "            threshold_clear = 0.15\n",
    "            if distance < threshold_clear:\n",
    "                # 手部握拳，清除绘画缓冲区\n",
    "                buffer = np.zeros((480,640, 3), np.uint8)\n",
    "            ################################### 手势识别 1 结束 #####################################\n",
    "            ################################### 手势识别 2：购买 ####################################\n",
    "            if recognize_buy(hand_landmarks, isCustom):\n",
    "                buy_text = \"Successful added to cart!\"\n",
    "                cv2.putText(buffer, buy_text, (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            ################################## 手势识别 2 结束 ######################################\n",
    "            ################################## 手势识别 3：付款 #####################################\n",
    "            if recognize_pay(hand_landmarks, isCustom):\n",
    "                pay_text = \"Please pay the bill by face recognition!\"\n",
    "                buffer = np.zeros((480,640, 3), np.uint8)\n",
    "                cv2.putText(buffer, pay_text, (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                state_buy = True\n",
    "            ################################## 手势识别 3 结束 ######################################\n",
    "            #若状态为可绘画，则绘制\n",
    "            if enable_drawing:\n",
    "                # 如果之前有记录的上一个位置，则绘制线段\n",
    "                if prev_x is not None and prev_y is not None:\n",
    "                    cv2.line(buffer, (prev_x, prev_y), (x, y), (0, 0, 255), 5)\n",
    "\n",
    "            # 更新上一个位置为当前位置\n",
    "            prev_x, prev_y = x, y\n",
    "\n",
    "            # 提示目前绘画开启状态\n",
    "            if index_move_distance < hover_distance_threshold and hover_duration > 10:\n",
    "                text = \"Hovering\" + str(hover_duration)\n",
    "            elif enable_drawing:\n",
    "                text = \"Drawing Enabled\"\n",
    "            else:\n",
    "                text = \"Drawing Disabled\"\n",
    "            cv2.putText(frame, text, (x, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    else:\n",
    "        prev_x, prev_y = None, None\n",
    "\n",
    "    # 将缓冲区中的线条叠加到摄像头画面上（若状态为可绘画）\n",
    "    # frame = cv2.add(frame, buffer)\n",
    "    # cv2.imshow('Project', frame)\n",
    "\n",
    "    if state_buy:\n",
    "        frame, isMatch, user = face_recognition_module(frame)\n",
    "        print(\"in\")\n",
    "        # cv2.imshow('Project', frame)\n",
    "        if isMatch:\n",
    "            print(\"match\")\n",
    "            finish_text = \"Payment complete! \" + user\n",
    "            cv2.putText(buffer, finish_text, (90, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            frame = cv2.add(frame, buffer)\n",
    "            cv2.imshow('Project', frame)\n",
    "            state_buy = False\n",
    "    # else:\n",
    "    #     cv2.imshow('Project', frame)\n",
    "\n",
    "    frame = cv2.add(frame, buffer)\n",
    "    cv2.imshow('Project', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
